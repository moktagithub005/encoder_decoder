{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceca9b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee66a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Dummy Dataset\n",
    "english_sentences = [\n",
    "    'hello', 'how are you', 'what is your name', 'good morning',\n",
    "    'good night', 'thank you', 'sorry', 'yes', 'no', 'please',\n",
    "    'where are you', 'i love you', 'what time is it', 'i am fine',\n",
    "    'see you later', 'goodbye', 'i am hungry', 'i am tired',\n",
    "    'what is this', 'where is the station', 'come here', 'go there',\n",
    "    'open the door', 'close the window', 'sit down', 'stand up',\n",
    "    'be careful', 'congratulations', 'happy birthday'\n",
    "]\n",
    "\n",
    "hindi_sentences = [\n",
    "    'नमस्ते', 'आप कैसे हैं', 'आपका नाम क्या है', 'सुप्रभात',\n",
    "    'शुभ रात्रि', 'धन्यवाद', 'माफ़ कीजिए', 'हाँ', 'नहीं', 'कृपया',\n",
    "    'आप कहाँ हैं', 'मैं आपसे प्यार करता हूँ', 'समय क्या हुआ है', 'मैं ठीक हूँ',\n",
    "    'बाद में मिलते हैं', 'अलविदा', 'मुझे भूख लगी है', 'मैं थक गया हूँ',\n",
    "    'यह क्या है', 'स्टेशन कहाँ है', 'यहाँ आओ', 'वहाँ जाओ',\n",
    "    'दरवाजा खोलो', 'खिड़की बंद करो', 'बैठ जाओ', 'खड़े हो जाओ',\n",
    "    'सावधान रहो', 'बधाई हो', 'जन्मदिन मुबारक हो'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89e072e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tokenizers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "eng_tokenizer = Tokenizer(filters='')\n",
    "hin_tokenizer = Tokenizer(filters='')\n",
    "\n",
    "eng_tokenizer.fit_on_texts(english_sentences)\n",
    "hin_tokenizer.fit_on_texts(hindi_sentences)\n",
    "\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "hin_vocab_size = len(hin_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2dcc388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Preprocess\n",
    "input_seq = eng_tokenizer.texts_to_sequences(english_sentences)\n",
    "target_seq = hin_tokenizer.texts_to_sequences(hindi_sentences)\n",
    "\n",
    "input_seq = pad_sequences(input_seq, padding='post')\n",
    "target_seq = pad_sequences(target_seq, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e50e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target input and target output (for teacher forcing)\n",
    "decoder_input = target_seq[:, :-1]\n",
    "decoder_output = target_seq[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3380339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Build Encoder-Decoder Model\n",
    "embed_dim = 64\n",
    "units = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dd10ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = tf.keras.Input(shape=(None,))\n",
    "encoder_emb = tf.keras.layers.Embedding(eng_vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs, state_h = tf.keras.layers.GRU(units, return_state=True)(encoder_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dea27ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "decoder_inputs = tf.keras.Input(shape=(None,))\n",
    "decoder_emb = tf.keras.layers.Embedding(hin_vocab_size, embed_dim)(decoder_inputs)\n",
    "decoder_gru = tf.keras.layers.GRU(units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _ = decoder_gru(decoder_emb, initial_state=state_h)\n",
    "decoder_dense = tf.keras.layers.Dense(hin_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c8b7ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,520</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)           │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>]         │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,095</span> │ gru_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m3,136\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m3,520\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)           │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),     │     \u001b[38;5;34m74,496\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │     \u001b[38;5;34m74,496\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m]         │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)  │      \u001b[38;5;34m7,095\u001b[0m │ gru_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">162,743</span> (635.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m162,743\u001b[0m (635.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">162,743</span> (635.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m162,743\u001b[0m (635.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model\n",
    "model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fe5660c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 182ms/step - accuracy: 0.3368 - loss: 3.9801 - val_accuracy: 0.6250 - val_loss: 3.8855\n",
      "Epoch 2/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6175 - loss: 3.8157 - val_accuracy: 0.6250 - val_loss: 3.6528\n",
      "Epoch 3/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6148 - loss: 3.4862 - val_accuracy: 0.6250 - val_loss: 3.0547\n",
      "Epoch 4/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6846 - loss: 2.5070 - val_accuracy: 0.6250 - val_loss: 1.9220\n",
      "Epoch 5/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5827 - loss: 1.8675 - val_accuracy: 0.6250 - val_loss: 2.3741\n",
      "Epoch 6/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6484 - loss: 1.6873 - val_accuracy: 0.6250 - val_loss: 2.0121\n",
      "Epoch 7/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5929 - loss: 1.6593 - val_accuracy: 0.6250 - val_loss: 1.9454\n",
      "Epoch 8/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6054 - loss: 1.6050 - val_accuracy: 0.6250 - val_loss: 1.9915\n",
      "Epoch 9/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6164 - loss: 1.4803 - val_accuracy: 0.6250 - val_loss: 2.2029\n",
      "Epoch 10/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6551 - loss: 1.2774 - val_accuracy: 0.6250 - val_loss: 2.3823\n",
      "Epoch 11/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6269 - loss: 1.3530 - val_accuracy: 0.6250 - val_loss: 2.3532\n",
      "Epoch 12/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6068 - loss: 1.3801 - val_accuracy: 0.6250 - val_loss: 2.3602\n",
      "Epoch 13/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6172 - loss: 1.3247 - val_accuracy: 0.6250 - val_loss: 2.5061\n",
      "Epoch 14/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5654 - loss: 1.4691 - val_accuracy: 0.6250 - val_loss: 2.6126\n",
      "Epoch 15/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6642 - loss: 1.0920 - val_accuracy: 0.6250 - val_loss: 2.6862\n",
      "Epoch 16/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5685 - loss: 1.3982 - val_accuracy: 0.6250 - val_loss: 2.7358\n",
      "Epoch 17/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5538 - loss: 1.4273 - val_accuracy: 0.6250 - val_loss: 2.8562\n",
      "Epoch 18/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6609 - loss: 1.0516 - val_accuracy: 0.6250 - val_loss: 3.0233\n",
      "Epoch 19/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6740 - loss: 0.9818 - val_accuracy: 0.6250 - val_loss: 3.0475\n",
      "Epoch 20/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6523 - loss: 1.0864 - val_accuracy: 0.6250 - val_loss: 3.2093\n",
      "Epoch 21/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6490 - loss: 1.0523 - val_accuracy: 0.6250 - val_loss: 3.2966\n",
      "Epoch 22/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7525 - loss: 0.7991 - val_accuracy: 0.6250 - val_loss: 3.4053\n",
      "Epoch 23/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7493 - loss: 0.8975 - val_accuracy: 0.6250 - val_loss: 3.5048\n",
      "Epoch 24/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7899 - loss: 0.7947 - val_accuracy: 0.6250 - val_loss: 3.5658\n",
      "Epoch 25/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7942 - loss: 0.7731 - val_accuracy: 0.6250 - val_loss: 3.6910\n",
      "Epoch 26/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7571 - loss: 0.8859 - val_accuracy: 0.6250 - val_loss: 3.6446\n",
      "Epoch 27/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8129 - loss: 0.6881 - val_accuracy: 0.6250 - val_loss: 3.8167\n",
      "Epoch 28/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7462 - loss: 0.9203 - val_accuracy: 0.6250 - val_loss: 3.7439\n",
      "Epoch 29/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8013 - loss: 0.7207 - val_accuracy: 0.6250 - val_loss: 3.9579\n",
      "Epoch 30/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8224 - loss: 0.6018 - val_accuracy: 0.6250 - val_loss: 3.8279\n",
      "Epoch 31/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8081 - loss: 0.6598 - val_accuracy: 0.6250 - val_loss: 4.1530\n",
      "Epoch 32/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7928 - loss: 0.6504 - val_accuracy: 0.6250 - val_loss: 3.7389\n",
      "Epoch 33/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8776 - loss: 0.5652 - val_accuracy: 0.6250 - val_loss: 4.2630\n",
      "Epoch 34/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8756 - loss: 0.4306 - val_accuracy: 0.6250 - val_loss: 3.7172\n",
      "Epoch 35/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8581 - loss: 0.5050 - val_accuracy: 0.6250 - val_loss: 3.8529\n",
      "Epoch 36/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8564 - loss: 0.4687 - val_accuracy: 0.6250 - val_loss: 4.5359\n",
      "Epoch 37/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8554 - loss: 0.5139 - val_accuracy: 0.6250 - val_loss: 3.8913\n",
      "Epoch 38/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9170 - loss: 0.4558 - val_accuracy: 0.6250 - val_loss: 3.9322\n",
      "Epoch 39/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8797 - loss: 0.4309 - val_accuracy: 0.6250 - val_loss: 4.1722\n",
      "Epoch 40/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9113 - loss: 0.3788 - val_accuracy: 0.6250 - val_loss: 4.1464\n",
      "Epoch 41/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9722 - loss: 0.3567 - val_accuracy: 0.6250 - val_loss: 4.0916\n",
      "Epoch 42/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9797 - loss: 0.3459 - val_accuracy: 0.6250 - val_loss: 4.1571\n",
      "Epoch 43/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9709 - loss: 0.2577 - val_accuracy: 0.6250 - val_loss: 4.2230\n",
      "Epoch 44/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9828 - loss: 0.2143 - val_accuracy: 0.6250 - val_loss: 4.1844\n",
      "Epoch 45/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9753 - loss: 0.2665 - val_accuracy: 0.6250 - val_loss: 4.2102\n",
      "Epoch 46/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9858 - loss: 0.2355 - val_accuracy: 0.6250 - val_loss: 4.2944\n",
      "Epoch 47/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9951 - loss: 0.2120 - val_accuracy: 0.6250 - val_loss: 4.2763\n",
      "Epoch 48/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9854 - loss: 0.2209 - val_accuracy: 0.6250 - val_loss: 4.2415\n",
      "Epoch 49/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9765 - loss: 0.2024 - val_accuracy: 0.6250 - val_loss: 4.3110\n",
      "Epoch 50/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9854 - loss: 0.1577 - val_accuracy: 0.6250 - val_loss: 4.3709\n",
      "Epoch 51/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9899 - loss: 0.1741 - val_accuracy: 0.6250 - val_loss: 4.3056\n",
      "Epoch 52/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9929 - loss: 0.1469 - val_accuracy: 0.6250 - val_loss: 4.3384\n",
      "Epoch 53/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9854 - loss: 0.1443 - val_accuracy: 0.6250 - val_loss: 4.3812\n",
      "Epoch 54/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1145 - val_accuracy: 0.6250 - val_loss: 4.3860\n",
      "Epoch 55/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9929 - loss: 0.1090 - val_accuracy: 0.6250 - val_loss: 4.4166\n",
      "Epoch 56/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9899 - loss: 0.0939 - val_accuracy: 0.6250 - val_loss: 4.3963\n",
      "Epoch 57/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.1066 - val_accuracy: 0.6250 - val_loss: 4.4147\n",
      "Epoch 58/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0964 - val_accuracy: 0.6250 - val_loss: 4.4237\n",
      "Epoch 59/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0910 - val_accuracy: 0.6250 - val_loss: 4.4368\n",
      "Epoch 60/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0804 - val_accuracy: 0.6250 - val_loss: 4.4598\n",
      "Epoch 61/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0755 - val_accuracy: 0.6250 - val_loss: 4.4637\n",
      "Epoch 62/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0615 - val_accuracy: 0.6250 - val_loss: 4.4904\n",
      "Epoch 63/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0743 - val_accuracy: 0.6250 - val_loss: 4.5220\n",
      "Epoch 64/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0537 - val_accuracy: 0.6250 - val_loss: 4.5154\n",
      "Epoch 65/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0469 - val_accuracy: 0.6250 - val_loss: 4.5178\n",
      "Epoch 66/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0442 - val_accuracy: 0.6250 - val_loss: 4.5302\n",
      "Epoch 67/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0411 - val_accuracy: 0.6250 - val_loss: 4.5485\n",
      "Epoch 68/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0523 - val_accuracy: 0.6250 - val_loss: 4.5653\n",
      "Epoch 69/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0394 - val_accuracy: 0.6250 - val_loss: 4.5696\n",
      "Epoch 70/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0265 - val_accuracy: 0.6250 - val_loss: 4.5765\n",
      "Epoch 71/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0304 - val_accuracy: 0.6250 - val_loss: 4.5878\n",
      "Epoch 72/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0330 - val_accuracy: 0.6250 - val_loss: 4.5963\n",
      "Epoch 73/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0301 - val_accuracy: 0.6250 - val_loss: 4.6118\n",
      "Epoch 74/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0291 - val_accuracy: 0.6250 - val_loss: 4.6237\n",
      "Epoch 75/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0247 - val_accuracy: 0.6250 - val_loss: 4.6334\n",
      "Epoch 76/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0277 - val_accuracy: 0.6250 - val_loss: 4.6323\n",
      "Epoch 77/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0258 - val_accuracy: 0.6250 - val_loss: 4.6454\n",
      "Epoch 78/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0283 - val_accuracy: 0.6250 - val_loss: 4.6631\n",
      "Epoch 79/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0226 - val_accuracy: 0.6250 - val_loss: 4.6679\n",
      "Epoch 80/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0193 - val_accuracy: 0.6250 - val_loss: 4.6686\n",
      "Epoch 81/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0208 - val_accuracy: 0.6250 - val_loss: 4.6814\n",
      "Epoch 82/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0211 - val_accuracy: 0.6250 - val_loss: 4.6906\n",
      "Epoch 83/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 0.6250 - val_loss: 4.6983\n",
      "Epoch 84/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 0.6250 - val_loss: 4.7054\n",
      "Epoch 85/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0168 - val_accuracy: 0.6250 - val_loss: 4.7078\n",
      "Epoch 86/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0175 - val_accuracy: 0.6250 - val_loss: 4.7085\n",
      "Epoch 87/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 0.6250 - val_loss: 4.7230\n",
      "Epoch 88/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 0.6250 - val_loss: 4.7285\n",
      "Epoch 89/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 0.6250 - val_loss: 4.7379\n",
      "Epoch 90/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.6250 - val_loss: 4.7431\n",
      "Epoch 91/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 0.6250 - val_loss: 4.7490\n",
      "Epoch 92/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 0.6250 - val_loss: 4.7582\n",
      "Epoch 93/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.6250 - val_loss: 4.7609\n",
      "Epoch 94/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 0.6250 - val_loss: 4.7661\n",
      "Epoch 95/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.6250 - val_loss: 4.7710\n",
      "Epoch 96/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.6250 - val_loss: 4.7816\n",
      "Epoch 97/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.6250 - val_loss: 4.7858\n",
      "Epoch 98/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.6250 - val_loss: 4.7935\n",
      "Epoch 99/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.6250 - val_loss: 4.7976\n",
      "Epoch 100/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.6250 - val_loss: 4.7997\n",
      "Epoch 101/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.6250 - val_loss: 4.8025\n",
      "Epoch 102/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.6250 - val_loss: 4.8057\n",
      "Epoch 103/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.6250 - val_loss: 4.8101\n",
      "Epoch 104/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.6250 - val_loss: 4.8131\n",
      "Epoch 105/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.6250 - val_loss: 4.8228\n",
      "Epoch 106/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.6250 - val_loss: 4.8281\n",
      "Epoch 107/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.6250 - val_loss: 4.8306\n",
      "Epoch 108/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.6250 - val_loss: 4.8347\n",
      "Epoch 109/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.6250 - val_loss: 4.8393\n",
      "Epoch 110/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.6250 - val_loss: 4.8461\n",
      "Epoch 111/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.6250 - val_loss: 4.8496\n",
      "Epoch 112/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.6250 - val_loss: 4.8559\n",
      "Epoch 113/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.6250 - val_loss: 4.8601\n",
      "Epoch 114/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.6250 - val_loss: 4.8650\n",
      "Epoch 115/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.6250 - val_loss: 4.8686\n",
      "Epoch 116/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.6250 - val_loss: 4.8717\n",
      "Epoch 117/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.6250 - val_loss: 4.8790\n",
      "Epoch 118/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.6250 - val_loss: 4.8837\n",
      "Epoch 119/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.6250 - val_loss: 4.8859\n",
      "Epoch 120/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.6250 - val_loss: 4.8892\n",
      "Epoch 121/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.6250 - val_loss: 4.8956\n",
      "Epoch 122/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.6250 - val_loss: 4.8975\n",
      "Epoch 123/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.6250 - val_loss: 4.8999\n",
      "Epoch 124/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.6250 - val_loss: 4.9011\n",
      "Epoch 125/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.6250 - val_loss: 4.9063\n",
      "Epoch 126/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.6250 - val_loss: 4.9103\n",
      "Epoch 127/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.6250 - val_loss: 4.9181\n",
      "Epoch 128/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.6250 - val_loss: 4.9242\n",
      "Epoch 129/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.6250 - val_loss: 4.9252\n",
      "Epoch 130/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.6250 - val_loss: 4.9285\n",
      "Epoch 131/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.6250 - val_loss: 4.9305\n",
      "Epoch 132/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.6250 - val_loss: 4.9333\n",
      "Epoch 133/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.6250 - val_loss: 4.9357\n",
      "Epoch 134/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.6250 - val_loss: 4.9406\n",
      "Epoch 135/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.6250 - val_loss: 4.9455\n",
      "Epoch 136/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.6250 - val_loss: 4.9497\n",
      "Epoch 137/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.6250 - val_loss: 4.9534\n",
      "Epoch 138/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.6250 - val_loss: 4.9559\n",
      "Epoch 139/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.6250 - val_loss: 4.9600\n",
      "Epoch 140/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.6250 - val_loss: 4.9628\n",
      "Epoch 141/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.6250 - val_loss: 4.9651\n",
      "Epoch 142/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.6250 - val_loss: 4.9664\n",
      "Epoch 143/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.6250 - val_loss: 4.9700\n",
      "Epoch 144/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.6250 - val_loss: 4.9732\n",
      "Epoch 145/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.6250 - val_loss: 4.9773\n",
      "Epoch 146/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.6250 - val_loss: 4.9811\n",
      "Epoch 147/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.6250 - val_loss: 4.9862\n",
      "Epoch 148/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.6250 - val_loss: 4.9905\n",
      "Epoch 149/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.6250 - val_loss: 4.9938\n",
      "Epoch 150/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.6250 - val_loss: 4.9960\n",
      "Epoch 151/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.6250 - val_loss: 4.9986\n",
      "Epoch 152/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.6250 - val_loss: 5.0014\n",
      "Epoch 153/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.6250 - val_loss: 5.0041\n",
      "Epoch 154/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.6250 - val_loss: 5.0075\n",
      "Epoch 155/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.6250 - val_loss: 5.0115\n",
      "Epoch 156/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.6250 - val_loss: 5.0146\n",
      "Epoch 157/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.6250 - val_loss: 5.0184\n",
      "Epoch 158/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.6250 - val_loss: 5.0204\n",
      "Epoch 159/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.6250 - val_loss: 5.0213\n",
      "Epoch 160/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.6250 - val_loss: 5.0248\n",
      "Epoch 161/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.6250 - val_loss: 5.0281\n",
      "Epoch 162/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.6250 - val_loss: 5.0308\n",
      "Epoch 163/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.6250 - val_loss: 5.0325\n",
      "Epoch 164/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.6250 - val_loss: 5.0352\n",
      "Epoch 165/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.6250 - val_loss: 5.0374\n",
      "Epoch 166/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.6250 - val_loss: 5.0386\n",
      "Epoch 167/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.6250 - val_loss: 5.0410\n",
      "Epoch 168/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.6250 - val_loss: 5.0441\n",
      "Epoch 169/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.6250 - val_loss: 5.0479\n",
      "Epoch 170/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.6250 - val_loss: 5.0515\n",
      "Epoch 171/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.6250 - val_loss: 5.0537\n",
      "Epoch 172/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.6250 - val_loss: 5.0569\n",
      "Epoch 173/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.6250 - val_loss: 5.0584\n",
      "Epoch 174/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.6250 - val_loss: 5.0607\n",
      "Epoch 175/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.6250 - val_loss: 5.0632\n",
      "Epoch 176/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.6250 - val_loss: 5.0661\n",
      "Epoch 177/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.6250 - val_loss: 5.0703\n",
      "Epoch 178/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.6250 - val_loss: 5.0722\n",
      "Epoch 179/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.6250 - val_loss: 5.0755\n",
      "Epoch 180/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.6250 - val_loss: 5.0770\n",
      "Epoch 181/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.6250 - val_loss: 5.0798\n",
      "Epoch 182/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.6250 - val_loss: 5.0808\n",
      "Epoch 183/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.6250 - val_loss: 5.0826\n",
      "Epoch 184/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.6250 - val_loss: 5.0843\n",
      "Epoch 185/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.6250 - val_loss: 5.0874\n",
      "Epoch 186/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.6250 - val_loss: 5.0899\n",
      "Epoch 187/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.6250 - val_loss: 5.0930\n",
      "Epoch 188/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.6250 - val_loss: 5.0954\n",
      "Epoch 189/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.6250 - val_loss: 5.0984\n",
      "Epoch 190/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.6250 - val_loss: 5.0997\n",
      "Epoch 191/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.6250 - val_loss: 5.1015\n",
      "Epoch 192/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.6250 - val_loss: 5.1042\n",
      "Epoch 193/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.6250 - val_loss: 5.1060\n",
      "Epoch 194/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.6250 - val_loss: 5.1079\n",
      "Epoch 195/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.6250 - val_loss: 5.1109\n",
      "Epoch 196/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.6250 - val_loss: 5.1127\n",
      "Epoch 197/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.6250 - val_loss: 5.1166\n",
      "Epoch 198/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.6250 - val_loss: 5.1179\n",
      "Epoch 199/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.6250 - val_loss: 5.1196\n",
      "Epoch 200/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.6250 - val_loss: 5.1228\n"
     ]
    }
   ],
   "source": [
    "# 6. Train\n",
    "history = model.fit(\n",
    "    [input_seq, decoder_input],\n",
    "    decoder_output[..., np.newaxis],\n",
    "    batch_size=4,\n",
    "    epochs=200,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfa2849a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# 7. Save the model\n",
    "model.save('translator.h5')\n",
    "import pickle\n",
    "\n",
    "with open('eng_tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(eng_tokenizer, f)\n",
    "with open('hin_tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(hin_tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b31b53fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 8. Plot Accuracy\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
